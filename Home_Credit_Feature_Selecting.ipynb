{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from missingpy import KNNImputer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "path = '../home_credit_data'\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "from memory_profiler import profile\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# from imputer import Imputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from missingpy import KNNImputer\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/home_credit_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REFUSED_RATE_DOWN_PAYMENT_MEAN</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MIN</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_RATE_DOWN_PAYMENT_MAX</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_RATE_DOWN_PAYMENT_MIN</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MEAN</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MAX</th>\n",
       "      <td>303648</td>\n",
       "      <td>85.234287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_APP_CREDIT_PERC_VAR</th>\n",
       "      <td>298034</td>\n",
       "      <td>83.658432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_VAR</th>\n",
       "      <td>284649</td>\n",
       "      <td>79.901249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <td>284559</td>\n",
       "      <td>79.875986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MEAN</th>\n",
       "      <td>284131</td>\n",
       "      <td>79.755846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MAX</th>\n",
       "      <td>284131</td>\n",
       "      <td>79.755846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MIN</th>\n",
       "      <td>284131</td>\n",
       "      <td>79.755846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MAX</th>\n",
       "      <td>284057</td>\n",
       "      <td>79.735074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <td>284057</td>\n",
       "      <td>79.735074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MIN</th>\n",
       "      <td>284057</td>\n",
       "      <td>79.735074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Total    Percent\n",
       "REFUSED_RATE_DOWN_PAYMENT_MEAN     303648  85.234287\n",
       "REFUSED_AMT_DOWN_PAYMENT_MIN       303648  85.234287\n",
       "REFUSED_RATE_DOWN_PAYMENT_MAX      303648  85.234287\n",
       "REFUSED_RATE_DOWN_PAYMENT_MIN      303648  85.234287\n",
       "REFUSED_AMT_DOWN_PAYMENT_MEAN      303648  85.234287\n",
       "REFUSED_AMT_DOWN_PAYMENT_MAX       303648  85.234287\n",
       "REFUSED_APP_CREDIT_PERC_VAR        298034  83.658432\n",
       "CC_AMT_PAYMENT_CURRENT_VAR         284649  79.901249\n",
       "CC_CNT_DRAWINGS_ATM_CURRENT_VAR    284559  79.875986\n",
       "CC_AMT_DRAWINGS_ATM_CURRENT_VAR    284559  79.875986\n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_VAR  284559  79.875986\n",
       "CC_CNT_DRAWINGS_POS_CURRENT_VAR    284559  79.875986\n",
       "CC_AMT_DRAWINGS_POS_CURRENT_VAR    284559  79.875986\n",
       "CC_CNT_DRAWINGS_OTHER_CURRENT_VAR  284559  79.875986\n",
       "CC_AMT_PAYMENT_CURRENT_MEAN        284131  79.755846\n",
       "CC_AMT_PAYMENT_CURRENT_MAX         284131  79.755846\n",
       "CC_AMT_PAYMENT_CURRENT_MIN         284131  79.755846\n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_MAX  284057  79.735074\n",
       "CC_AMT_DRAWINGS_ATM_CURRENT_MEAN   284057  79.735074\n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_MIN  284057  79.735074"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing data\n",
    "total = df.isnull().sum().sort_values(ascending = False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
    "missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Light GBM feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances092319.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "stratified = False\n",
    "num_folds = 5\n",
    "submission_file_name = \"results092319.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307507, 799), test shape: (48744, 799)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.775477\ttraining's binary_logloss: 0.248214\tvalid_1's auc: 0.763649\tvalid_1's binary_logloss: 0.250773\n",
      "[200]\ttraining's auc: 0.789871\ttraining's binary_logloss: 0.239236\tvalid_1's auc: 0.774013\tvalid_1's binary_logloss: 0.243577\n",
      "[300]\ttraining's auc: 0.80018\ttraining's binary_logloss: 0.234562\tvalid_1's auc: 0.780388\tvalid_1's binary_logloss: 0.240568\n",
      "[400]\ttraining's auc: 0.807789\ttraining's binary_logloss: 0.231285\tvalid_1's auc: 0.783952\tvalid_1's binary_logloss: 0.238931\n",
      "[500]\ttraining's auc: 0.813674\ttraining's binary_logloss: 0.228774\tvalid_1's auc: 0.786395\tvalid_1's binary_logloss: 0.23787\n",
      "[600]\ttraining's auc: 0.818572\ttraining's binary_logloss: 0.226662\tvalid_1's auc: 0.788084\tvalid_1's binary_logloss: 0.237116\n",
      "[700]\ttraining's auc: 0.822896\ttraining's binary_logloss: 0.224846\tvalid_1's auc: 0.789315\tvalid_1's binary_logloss: 0.236606\n",
      "[800]\ttraining's auc: 0.826751\ttraining's binary_logloss: 0.223227\tvalid_1's auc: 0.790191\tvalid_1's binary_logloss: 0.236249\n",
      "[900]\ttraining's auc: 0.830681\ttraining's binary_logloss: 0.221601\tvalid_1's auc: 0.790869\tvalid_1's binary_logloss: 0.235961\n",
      "[1000]\ttraining's auc: 0.834407\ttraining's binary_logloss: 0.220052\tvalid_1's auc: 0.791464\tvalid_1's binary_logloss: 0.235701\n",
      "[1100]\ttraining's auc: 0.837902\ttraining's binary_logloss: 0.218604\tvalid_1's auc: 0.791877\tvalid_1's binary_logloss: 0.235519\n",
      "[1200]\ttraining's auc: 0.841337\ttraining's binary_logloss: 0.2172\tvalid_1's auc: 0.792365\tvalid_1's binary_logloss: 0.235339\n",
      "[1300]\ttraining's auc: 0.844726\ttraining's binary_logloss: 0.215815\tvalid_1's auc: 0.792753\tvalid_1's binary_logloss: 0.235192\n",
      "[1400]\ttraining's auc: 0.847807\ttraining's binary_logloss: 0.214517\tvalid_1's auc: 0.793051\tvalid_1's binary_logloss: 0.235066\n",
      "[1500]\ttraining's auc: 0.850871\ttraining's binary_logloss: 0.213234\tvalid_1's auc: 0.793381\tvalid_1's binary_logloss: 0.234937\n",
      "[1600]\ttraining's auc: 0.853899\ttraining's binary_logloss: 0.211949\tvalid_1's auc: 0.793683\tvalid_1's binary_logloss: 0.234835\n",
      "[1700]\ttraining's auc: 0.856761\ttraining's binary_logloss: 0.210741\tvalid_1's auc: 0.793823\tvalid_1's binary_logloss: 0.234775\n",
      "[1800]\ttraining's auc: 0.85948\ttraining's binary_logloss: 0.209535\tvalid_1's auc: 0.793888\tvalid_1's binary_logloss: 0.234752\n",
      "[1900]\ttraining's auc: 0.862288\ttraining's binary_logloss: 0.208306\tvalid_1's auc: 0.793899\tvalid_1's binary_logloss: 0.23473\n",
      "[2000]\ttraining's auc: 0.865048\ttraining's binary_logloss: 0.207093\tvalid_1's auc: 0.794053\tvalid_1's binary_logloss: 0.234676\n",
      "[2100]\ttraining's auc: 0.867609\ttraining's binary_logloss: 0.205951\tvalid_1's auc: 0.79422\tvalid_1's binary_logloss: 0.234621\n",
      "[2200]\ttraining's auc: 0.870016\ttraining's binary_logloss: 0.204866\tvalid_1's auc: 0.794256\tvalid_1's binary_logloss: 0.234615\n",
      "[2300]\ttraining's auc: 0.872636\ttraining's binary_logloss: 0.203668\tvalid_1's auc: 0.79437\tvalid_1's binary_logloss: 0.23457\n",
      "[2400]\ttraining's auc: 0.875318\ttraining's binary_logloss: 0.202439\tvalid_1's auc: 0.794356\tvalid_1's binary_logloss: 0.234552\n",
      "[2500]\ttraining's auc: 0.877668\ttraining's binary_logloss: 0.201357\tvalid_1's auc: 0.794394\tvalid_1's binary_logloss: 0.234549\n"
     ]
    }
   ],
   "source": [
    "# Divide in training/validation and test data\n",
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "del df\n",
    "gc.collect()\n",
    "# Cross validation model\n",
    "if stratified:\n",
    "    folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "else:\n",
    "    folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "    train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "    # LightGBM parameters found by Bayesian optimization\n",
    "# =============================================================================\n",
    "#    clf = LGBMClassifier(\n",
    "#         nthread=4,\n",
    "#         n_estimators=10000,\n",
    "#         learning_rate=0.02,\n",
    "#         num_leaves=34,\n",
    "#         colsample_bytree=0.9497036,\n",
    "#         subsample=0.8715623,\n",
    "#         max_depth=8,\n",
    "#         reg_alpha=0.041545473,\n",
    "#         reg_lambda=0.0735294,\n",
    "#         min_split_gain=0.0222415,\n",
    "#         min_child_weight=39.3259775,\n",
    "#         silent=-1,\n",
    "#         verbose=-1, )\n",
    "# =============================================================================\n",
    "    clf = LGBMClassifier(\n",
    "        nthread=4,\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=56,\n",
    "        colsample_bytree=0.45,\n",
    "        subsample=0.91,\n",
    "        max_depth=5,\n",
    "        reg_alpha=3.99,\n",
    "        reg_lambda=0.43,\n",
    "        min_split_gain=0.077649,\n",
    "        min_child_weight=32.5443,\n",
    "        silent=-1,\n",
    "        verbose=-1, )\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "    eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n",
    "\n",
    "oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = feats\n",
    "fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "fold_importance_df[\"fold\"] = n_fold + 1\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "del clf, train_x, train_y, valid_x, valid_y\n",
    "gc.collect()\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "# Write submission file and plot feature importance\n",
    "if not debug:\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "display_importances(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
