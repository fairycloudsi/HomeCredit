{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# from light_gbm import kfold_lightgbm\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, image_name):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout\n",
    "    plt.savefig(image_name)\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, submission_file_name, image_name, train_record_file, stratified = False, debug= False, seed=123):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                             label=train_df['TARGET'].iloc[train_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "        dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                             label=train_df['TARGET'].iloc[valid_idx], \n",
    "                             free_raw_data=False, silent=True)\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'nthread': 4,\n",
    "            'learning_rate': 0.02,  # 02,\n",
    "            'num_leaves': 20,\n",
    "            'colsample_bytree': 0.9497036,\n",
    "            'subsample': 0.8715623,\n",
    "            'subsample_freq': 1,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': 0.041545473,\n",
    "            'reg_lambda': 0.0735294,\n",
    "            'min_split_gain': 0.0222415,\n",
    "            'min_child_weight': 60, # 39.3259775,\n",
    "            'seed': 0,\n",
    "            'verbose': -1,\n",
    "            'metric': 'auc',\n",
    "        }\n",
    "        \n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds=200,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(dvalid.label, oof_preds[valid_idx])))\n",
    "#         del clf, dtrain, dvalid\n",
    "        del dtrain, dvalid\n",
    "        gc.collect()\n",
    "    roc_auc = roc_auc_score(train_df['TARGET'], oof_preds)\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    with open(train_record_file,'a') as f:\n",
    "        f.write('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds)+'\\n')\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        sub_df = test_df[['SK_ID_CURR']].copy()\n",
    "        sub_df['TARGET'] = sub_preds\n",
    "        sub_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df, image_name)\n",
    "    return feature_importance_df, clf, roc_auc\n",
    "\n",
    "\n",
    "# all_feature_df = pd.read_csv('All_features.csv')\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def original_application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('../input/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('../input/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "    live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('../input/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('../input/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "    live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "    inc_by_org = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    # df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    # df['NEW_DOC_IND_AVG'] = df[docs].mean(axis=1)\n",
    "    # df['NEW_DOC_IND_STD'] = df[docs].std(axis=1)\n",
    "    # df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    # df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n",
    "    # df['NEW_LIVE_IND_STD'] = df[live].std(axis=1)\n",
    "    # df['NEW_LIVE_IND_KURT'] = df[live].kurtosis(axis=1)\n",
    "    # df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
    "    # df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(inc_by_org)\n",
    "    # df['NEW_EMPLOY_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    # df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n",
    "    # df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    # df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    # df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    # df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n",
    "    # df['NEW_CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    # df['NEW_CAR_TO_EMPLOY_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    # df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "    # df['NEW_PHONE_TO_EMPLOY_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
    "    # df['NEW_CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def record_importance(feat_importance, record_file_name):\n",
    "    all_features_sort = feat_importance[[\"feature\",\"importance\"]]\\\n",
    "    .groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n",
    "    important_list = []\n",
    "    # print(all_features_sort['importance']['NEW_EXT_SOURCES_MEAN'])\n",
    "    important_list = all_features_sort.index.values\n",
    "    with open(record_file_name,'w') as f:\n",
    "        for name in important_list:\n",
    "            f.write(str(name) + '\\t'+ str(all_features_sort['importance'][name])+'\\n')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_train_df = application_train_test()\n",
    "def basic_feature_test(original_train_df, test_num):\n",
    "    score_sum = []\n",
    "    for i in range(test_num):\n",
    "        feat_importance, clf, score = kfold_lightgbm(original_train_df, num_folds = 5, train_record_file = './new_features/Original_features_train.txt'.format(i), submission_file_name = './new_features/Original_features_{}.csv'.format(i), \\\n",
    "        image_name = './new_features/Original_importance.png'.format(i), stratified= False, debug = False, seed = i)\n",
    "        record_importance(feat_importance, './new_features/Original_features_importance_rank.txt'.format(i))\n",
    "        score_sum.append(score)\n",
    "    return sum(score_sum)/len(score_sum)\n",
    "\n",
    "def new_single_feature_test(new_train_df, feature_name, test_num):\n",
    "    score_sum = []\n",
    "    for i in range(test_num):       \n",
    "        feat_importance, clf, score = kfold_lightgbm(new_train_df, num_folds = 5, train_record_file = './new_features/{}_train.txt'.format(feature_name), submission_file_name = './new_features/new_feature_{}.csv'.format(feature_name), \\\n",
    "        image_name = './new_features/{}_importance.png'.format(feature_name), stratified= False, debug = False, seed = i)\n",
    "        record_importance(feat_importance,'./new_features/{}_importance_rank.txt'.format(feature_name))\n",
    "        score_sum.append(score)\n",
    "    return sum(score_sum)/len(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifantian/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307507, 243), test shape: (48744, 243)\n",
      "Fold  1 AUC : 0.768332\n",
      "Fold  2 AUC : 0.762283\n",
      "Fold  3 AUC : 0.753738\n",
      "Fold  4 AUC : 0.759918\n",
      "Fold  5 AUC : 0.765644\n",
      "Full AUC score 0.761944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifantian/anaconda/lib/python3.5/site-packages/seaborn/categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    }
   ],
   "source": [
    "score_dict = dict()\n",
    "df = original_application_train_test()\n",
    "score_dict['original'] = basic_feature_test(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifantian/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.776609\n",
      "Fold  2 AUC : 0.770611\n",
      "Fold  3 AUC : 0.761543\n",
      "Fold  4 AUC : 0.768248\n",
      "Fold  5 AUC : 0.774085\n",
      "Full AUC score 0.770172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifantian/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/Users/yifantian/anaconda/lib/python3.5/site-packages/seaborn/categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768897\n",
      "Fold  2 AUC : 0.762443\n",
      "Fold  3 AUC : 0.754656\n",
      "Fold  4 AUC : 0.760148\n",
      "Fold  5 AUC : 0.766903\n",
      "Full AUC score 0.762556\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768597\n",
      "Fold  2 AUC : 0.762542\n",
      "Fold  3 AUC : 0.753952\n",
      "Fold  4 AUC : 0.759910\n",
      "Fold  5 AUC : 0.765751\n",
      "Full AUC score 0.762080\n",
      "243\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768803\n",
      "Fold  2 AUC : 0.762597\n",
      "Fold  3 AUC : 0.753854\n",
      "Fold  4 AUC : 0.759805\n",
      "Fold  5 AUC : 0.765699\n",
      "Full AUC score 0.762105\n",
      "243\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768967\n",
      "Fold  2 AUC : 0.762409\n",
      "Fold  3 AUC : 0.754388\n",
      "Fold  4 AUC : 0.760070\n",
      "Fold  5 AUC : 0.765891\n",
      "Full AUC score 0.762309\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768497\n",
      "Fold  2 AUC : 0.762114\n",
      "Fold  3 AUC : 0.753950\n",
      "Fold  4 AUC : 0.759363\n",
      "Fold  5 AUC : 0.765575\n",
      "Full AUC score 0.761852\n",
      "243\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768481\n",
      "Fold  2 AUC : 0.762379\n",
      "Fold  3 AUC : 0.753802\n",
      "Fold  4 AUC : 0.759345\n",
      "Fold  5 AUC : 0.765650\n",
      "Full AUC score 0.761875\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768377\n",
      "Fold  2 AUC : 0.762379\n",
      "Fold  3 AUC : 0.753840\n",
      "Fold  4 AUC : 0.759419\n",
      "Fold  5 AUC : 0.765650\n",
      "Full AUC score 0.761885\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768624\n",
      "Fold  2 AUC : 0.762164\n",
      "Fold  3 AUC : 0.753945\n",
      "Fold  4 AUC : 0.759675\n",
      "Fold  5 AUC : 0.765534\n",
      "Full AUC score 0.761928\n",
      "NEW_INC_BY_ORG\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768086\n",
      "Fold  2 AUC : 0.762201\n",
      "Fold  3 AUC : 0.754205\n",
      "Fold  4 AUC : 0.759838\n",
      "Fold  5 AUC : 0.765385\n",
      "Full AUC score 0.761873\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768834\n",
      "Fold  2 AUC : 0.762138\n",
      "Fold  3 AUC : 0.753979\n",
      "Fold  4 AUC : 0.759964\n",
      "Fold  5 AUC : 0.765806\n",
      "Full AUC score 0.762096\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768899\n",
      "Fold  2 AUC : 0.762068\n",
      "Fold  3 AUC : 0.753726\n",
      "Fold  4 AUC : 0.759571\n",
      "Fold  5 AUC : 0.765065\n",
      "Full AUC score 0.761830\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768377\n",
      "Fold  2 AUC : 0.762059\n",
      "Fold  3 AUC : 0.753078\n",
      "Fold  4 AUC : 0.760226\n",
      "Fold  5 AUC : 0.765158\n",
      "Full AUC score 0.761713\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768113\n",
      "Fold  2 AUC : 0.762049\n",
      "Fold  3 AUC : 0.753601\n",
      "Fold  4 AUC : 0.759565\n",
      "Fold  5 AUC : 0.765324\n",
      "Full AUC score 0.761672\n",
      "NEW_SCORES_STD\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768586\n",
      "Fold  2 AUC : 0.762008\n",
      "Fold  3 AUC : 0.753833\n",
      "Fold  4 AUC : 0.759568\n",
      "Fold  5 AUC : 0.765610\n",
      "Full AUC score 0.761871\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768544\n",
      "Fold  2 AUC : 0.762249\n",
      "Fold  3 AUC : 0.753675\n",
      "Fold  4 AUC : 0.758969\n",
      "Fold  5 AUC : 0.765384\n",
      "Full AUC score 0.761709\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768670\n",
      "Fold  2 AUC : 0.762445\n",
      "Fold  3 AUC : 0.753989\n",
      "Fold  4 AUC : 0.759615\n",
      "Fold  5 AUC : 0.765460\n",
      "Full AUC score 0.761998\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768404\n",
      "Fold  2 AUC : 0.762348\n",
      "Fold  3 AUC : 0.753801\n",
      "Fold  4 AUC : 0.759875\n",
      "Fold  5 AUC : 0.765205\n",
      "Full AUC score 0.761888\n",
      "Starting LightGBM. Train shape: (307507, 244), test shape: (48744, 244)\n",
      "Fold  1 AUC : 0.768367\n",
      "Fold  2 AUC : 0.762631\n",
      "Fold  3 AUC : 0.754189\n",
      "Fold  4 AUC : 0.759740\n",
      "Fold  5 AUC : 0.765614\n",
      "Full AUC score 0.762058\n"
     ]
    }
   ],
   "source": [
    "df = original_application_train_test()\n",
    "original_length = len(df.columns)\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_CREDIT_TO_ANNUITY_RATIO'] = new_df['AMT_CREDIT'] / new_df['AMT_ANNUITY']\n",
    "    score_dict['NEW_CREDIT_TO_ANNUITY_RATIO'] = new_single_feature_test(new_df, 'NEW_CREDIT_TO_ANNUITY_RATIO',1)\n",
    "except:\n",
    "    print('NEW_CREDIT_TO_ANNUITY_RATIO')\n",
    "print(len(df.columns))\n",
    "assert len(df.columns) == original_length\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_CREDIT_TO_GOODS_RATIO'] = new_df['AMT_CREDIT'] / new_df['AMT_GOODS_PRICE']\n",
    "    score_dict['NEW_CREDIT_TO_GOODS_RATIO'] = new_single_feature_test(new_df, 'NEW_CREDIT_TO_GOODS_RATIO',1)\n",
    "except:\n",
    "    print('NEW_CREDIT_TO_GOODS_RATIO')\n",
    "    print(len(df.columns))\n",
    "    assert len(df.columns) == original_length\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_DOC_IND_AVG'] = new_df[docs].mean(axis=1)\n",
    "    score_dict['NEW_DOC_IND_AVG'] = new_single_feature_test(new_df, 'NEW_DOC_IND_AVG',1)\n",
    "except:\n",
    "    print('NEW_DOC_IND_AVG')\n",
    "print(len(df.columns))\n",
    "assert len(df.columns) == original_length\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_DOC_IND_STD'] = new_df[docs].std(axis=1)\n",
    "    score_dict['NEW_DOC_IND_STD'] = new_single_feature_test(new_df, 'NEW_DOC_IND_STD',1)\n",
    "except:\n",
    "    print('NEW_DOC_IND_STD')\n",
    "print(len(df.columns))\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_DOC_IND_KURT'] = new_df[docs].kurtosis(axis=1)\n",
    "    score_dict['NEW_DOC_IND_KURT'] = new_single_feature_test(new_df, 'NEW_DOC_IND_KURT',1)\n",
    "except:\n",
    "    print('NEW_DOC_IND_KURT')\n",
    "    print(len(df.columns))\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_LIVE_IND_SUM'] = new_df[live].sum(axis=1)\n",
    "    score_dict['NEW_LIVE_IND_SUM'] = new_single_feature_test(new_df, 'NEW_LIVE_IND_SUM',1)\n",
    "except:\n",
    "    print('NEW_LIVE_IND_SUM')\n",
    "print(len(df.columns))\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_LIVE_IND_STD'] = new_df[live].std(axis=1)\n",
    "    score_dict['NEW_LIVE_IND_STD'] = new_single_feature_test(new_df, 'NEW_LIVE_IND_STD',1)\n",
    "except:\n",
    "    print('NEW_LIVE_IND_STD')\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_LIVE_IND_KURT'] = new_df[live].kurtosis(axis=1)\n",
    "    score_dict['NEW_LIVE_IND_KURT'] = new_single_feature_test(new_df, 'NEW_LIVE_IND_KURT',1)\n",
    "except:\n",
    "    print('NEW_LIVE_IND_KURT')\n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_INC_PER_CHLD'] = new_df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
    "    score_dict['NEW_INC_PER_CHLD'] = new_single_feature_test(new_df, 'NEW_INC_PER_CHLD',1)\n",
    "except:\n",
    "    print('NEW_INC_PER_CHLD')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_INC_BY_ORG'] = new_df['ORGANIZATION_TYPE'].map(inc_by_org)\n",
    "    score_dict['NEW_INC_BY_ORG'] = new_single_feature_test(new_df, 'NEW_INC_BY_ORG',1)\n",
    "except:\n",
    "    print('NEW_INC_BY_ORG')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_EMPLOY_TO_BIRTH_RATIO'] = new_df['DAYS_EMPLOYED'] / new_df['DAYS_BIRTH']\n",
    "    score_dict['NEW_EMPLOY_TO_BIRTH_RATIO'] = new_single_feature_test(new_df, 'NEW_EMPLOY_TO_BIRTH_RATIO',1)\n",
    "except:\n",
    "    print('NEW_EMPLOY_TO_BIRTH_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_ANNUITY_TO_INCOME_RATIO'] = new_df['AMT_ANNUITY'] / (1 + new_df['AMT_INCOME_TOTAL'])\n",
    "    score_dict['NEW_ANNUITY_TO_INCOME_RATIO'] = new_single_feature_test(new_df, 'NEW_ANNUITY_TO_INCOME_RATIO',1)\n",
    "except:\n",
    "    print('NEW_ANNUITY_TO_INCOME_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_SOURCES_PROD'] = new_df['EXT_SOURCE_1'] * new_df['EXT_SOURCE_2'] * new_df['EXT_SOURCE_3']\n",
    "    score_dict['NEW_SOURCES_PROD'] = new_single_feature_test(new_df, 'NEW_SOURCES_PROD',1)\n",
    "except:\n",
    "    print('NEW_SOURCES_PROD')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_EXT_SOURCES_MEAN'] = new_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    score_dict['NEW_EXT_SOURCES_MEAN'] = new_single_feature_test(new_df, 'NEW_EXT_SOURCES_MEAN',1)\n",
    "except:\n",
    "    print('NEW_EXT_SOURCES_MEAN')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_SCORES_STD'] = new_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    score_dict['NEW_SCORES_STD'] = new_single_feature_test(new_df, 'NEW_SCORES_STD',1)\n",
    "except:\n",
    "    print('NEW_SCORES_STD')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_SCORES_STD'] = new_df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n",
    "    score_dict['NEW_SCORES_STD'] = new_single_feature_test(new_df, 'NEW_SCORES_STD',1)\n",
    "except:\n",
    "    print('NEW_SCORES_STD')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_CAR_TO_BIRTH_RATIO'] = new_df['OWN_CAR_AGE'] / new_df['DAYS_BIRTH']\n",
    "    score_dict['NEW_CAR_TO_BIRTH_RATIO'] = new_single_feature_test(new_df, 'NEW_CAR_TO_BIRTH_RATIO',1)\n",
    "except:\n",
    "    print('NEW_CAR_TO_BIRTH_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_CAR_TO_EMPLOY_RATIO'] = new_df['OWN_CAR_AGE'] / new_df['DAYS_EMPLOYED']\n",
    "    score_dict['NEW_CAR_TO_EMPLOY_RATIO'] = new_single_feature_test(new_df, 'NEW_CAR_TO_EMPLOY_RATIO',1)\n",
    "except:\n",
    "    print('NEW_CAR_TO_EMPLOY_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_PHONE_TO_BIRTH_RATIO'] = new_df['DAYS_LAST_PHONE_CHANGE'] / new_df['DAYS_BIRTH']\n",
    "    score_dict['NEW_PHONE_TO_BIRTH_RATIO'] = new_single_feature_test(new_df, 'NEW_PHONE_TO_BIRTH_RATIO',1)\n",
    "except:\n",
    "    print('NEW_PHONE_TO_BIRTH_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_PHONE_TO_EMPLOY_RATIO'] = new_df['DAYS_LAST_PHONE_CHANGE'] / new_df['DAYS_EMPLOYED']\n",
    "    score_dict['NEW_PHONE_TO_EMPLOY_RATIO'] = new_single_feature_test(new_df, 'NEW_PHONE_TO_EMPLOY_RATIO',1)\n",
    "except:\n",
    "    print('NEW_PHONE_TO_EMPLOY_RATIO')  \n",
    "\n",
    "new_df = df.copy()\n",
    "try:\n",
    "    new_df['NEW_CREDIT_TO_INCOME_RATIO'] = new_df['AMT_CREDIT'] / new_df['AMT_INCOME_TOTAL']\n",
    "    score_dict['NEW_CREDIT_TO_INCOME_RATIO'] = new_single_feature_test(new_df, 'NEW_CREDIT_TO_INCOME_RATIO',1)\n",
    "except:\n",
    "    print('NEW_CREDIT_TO_INCOME_RATIO')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW_CREDIT_TO_ANNUITY_RATIO : 0.7701718897950962\n",
      "NEW_CREDIT_TO_GOODS_RATIO : 0.7625557909334466\n",
      "NEW_DOC_IND_KURT : 0.7623092532609511\n",
      "NEW_DOC_IND_STD : 0.7621047141082732\n",
      "NEW_ANNUITY_TO_INCOME_RATIO : 0.7620956222284385\n",
      "NEW_DOC_IND_AVG : 0.7620804281030955\n",
      "NEW_CREDIT_TO_INCOME_RATIO : 0.7620576039977538\n",
      "NEW_PHONE_TO_BIRTH_RATIO : 0.7619975364301655\n",
      "original : 0.7619437351247256\n",
      "NEW_INC_PER_CHLD : 0.7619278283606187\n",
      "NEW_PHONE_TO_EMPLOY_RATIO : 0.7618876348788381\n",
      "NEW_LIVE_IND_KURT : 0.7618848233685779\n",
      "NEW_LIVE_IND_STD : 0.7618751755991575\n",
      "NEW_EMPLOY_TO_BIRTH_RATIO : 0.7618725661528378\n",
      "NEW_CAR_TO_BIRTH_RATIO : 0.7618712667021504\n",
      "NEW_LIVE_IND_SUM : 0.7618523747211939\n",
      "NEW_SOURCES_PROD : 0.7618296976750811\n",
      "NEW_EXT_SOURCES_MEAN : 0.7617132403031236\n",
      "NEW_CAR_TO_EMPLOY_RATIO : 0.7617093044737577\n",
      "NEW_SCORES_STD : 0.7616722482555295\n"
     ]
    }
   ],
   "source": [
    "sorted_names = sorted(score_dict, key=score_dict.__getitem__, reverse=True)\n",
    "for k in sorted_names:\n",
    "    print(\"{} : {}\".format(k, score_dict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "247\n"
     ]
    }
   ],
   "source": [
    "ratio_tuples = [('EXT_SOURCE_3','AMT_ANNUITY'),\n",
    "               ('EXT_SOURCE_2','AMT_CREDIT'),\n",
    "               ('AMT_ANNUITY','DAYS_BIRTH'),\n",
    "               ('AMT_CREDIT','DAYS_EMPLOYED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in ratio_tuples:\n",
    "    new_df = df.copy()\n",
    "    try:\n",
    "        new_feature_name = t[0]+'_'+t[1]+'_ratio'\n",
    "        execline = \"new_df['{}'] = new_df['{}'] / new_df['{}']\".format(new_feature_name,t[0],t[1])\n",
    "        print(execline)\n",
    "        exec(execline)\n",
    "        score_dict[new_feature_name] = new_single_feature_test(new_df, new_feature_name,1)\n",
    "    except:\n",
    "        print('new feature: {} is wrong'.format(new_feature_name))\n",
    "        assert len(df.columns) == original_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEW_CREDIT_TO_ANNUITY_RATIO'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_names = sorted(score_dict, key=score_dict.__getitem__, reverse=True)\n",
    "for k in sorted_names:\n",
    "    print(\"{} : {}\".format(k, score_dict[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
